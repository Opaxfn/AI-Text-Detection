import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from textblob import TextBlob
from langdetect import detect

def is_ai_text(text):
    # Initialize a variable to store the AI score of the text
    score = 0
    # Split the text into words
    words = word_tokenize(text)
    # Count the number of unique words
    unique_words = len(set(words))
    # Count the number of total words
    total_words = len(words)
    # If the number of unique words is less than 20% of the total words,
    # it is likely that the text was generated by an AI
    if unique_words / total_words < 0.2:
        score += 1
    # Use TextBlob Library to perform NLP Tasks
    textBlob = TextBlob(text)
    # Extract the POS tags of the words in the text
    pos_tags = textBlob.tags
    # Initialize a variable to store the number of nouns in the text
    nouns = 0
    # Iterate through the POS tags and count the number of nouns
    for tag in pos_tags:
        if tag[1] in ['NN', 'NNS', 'NNP', 'NNPS']:
            nouns += 1
    # If the number of nouns is less than 20% of the total words,
    # it is likely that the text was generated by an AI
    if nouns / total_words < 0.2:
        score += 1
    # Use language detection library to detect the language of the text
    language = detect(text)
    # If the text is not written in english
    if language != 'en':
        score += 1
    # check the wording of the text
    stop_words = set(stopwords.words('english'))
    words = word_tokenize(text)
    filtered_sentence = [w for w in words if not w in stop_words]
    word_freq = nltk.FreqDist(filtered_sentence)
    if word_freq.most_common(10)[0][1] > (total_words/2):
        score +=1
    # return the percentage of likelihood of the text being written by an AI
    return (score/4)*100
